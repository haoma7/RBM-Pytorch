{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "class BinaryRBM():\n",
    "    \n",
    "    # RBM Initialization\n",
    "    def __init__(self, num_v, num_h, num_l, device=\"CPU\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_v (int): the number of nodes in the visible layer\n",
    "            num_h (int): the number of nodes in the hidden layer \n",
    "            device (str): CPU or GPU mode\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_v = num_v # the number of visible nodes\n",
    "        self.num_h = num_h # the number of hidden nodes\n",
    "        self.num_l = num_l # the number of label nodes (which are part of the visible layer)\n",
    "\n",
    "        if device == \"GPU\" and not torch.cuda.is_available():\n",
    "            raise ValueError(\"GPU is not supported\")\n",
    "        elif device == \"GPU\" and torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "        # normalization to ensure stability ? \n",
    "        self.w_v = torch.randn(num_h, num_v, device=self.device, dtype=torch.float32) / np.sqrt(num_v)\n",
    "        self.w_l = torch.randn(num_h, num_l, device=self.device, dtype=torch.float32) / np.sqrt(num_l)\n",
    "\n",
    "        self.b = torch.zeros(num_v, device=self.device, dtype=torch.float32).unsqueeze(1) # bias (column) vector for the visible layer\n",
    "        self.c = torch.zeros(num_h, device=self.device, dtype=torch.float32).unsqueeze(1) # bias (column) vector for the hidden layer\n",
    "\n",
    "    def idx2onehot(self, idx, n):\n",
    "\n",
    "        assert torch.max(idx).item() < n and idx.dim() == 1\n",
    "        idx2dim = idx.view(-1,1) # change from 1-dim tensor to 2-dim tensor\n",
    "        onehot = torch.zeros(idx2dim.size(0),n).scatter_(1,idx2dim,1)\n",
    "\n",
    "        return onehot\n",
    "\n",
    "\n",
    "\n",
    "    # Calculation of the free energy F(v)\n",
    "    def free_energy_func(self, v, l):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        v (torch.Tensor): the visible states\n",
    "\n",
    "        Returns:\n",
    "        free_energy (torch.Tensor): the free energy F(v) (c.f. Eq (12))\n",
    "\n",
    "        \"\"\"\n",
    "        # c.f. Eq.(12)\n",
    "        # .sum(0) represents the summation of different rows\n",
    "        # F.softplus(x) calculates log(1+exp(x))\n",
    "        \n",
    "        return -torch.matmul(self.b.t(),v.to(device=self.device)) - F.softplus(torch.addmm(self.c,torch.cat((self.w_v,self.w_l),1),torch.cat((v.to(device=self.device),l.to(device=self.device)),0))).sum(0)\n",
    "\n",
    "    def sample_h_given_v(self, v, label):\n",
    "        \"\"\"\n",
    "          Args:\n",
    "        v (torch.Tensor): the visible states\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "        sampled_h (torch.Tensor): the sample h according to Eq.(17). \n",
    "                                  It is a column vector that contains 0 or 1. \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        return (torch.addmm(self.c, torch.cat((self.w_v,self.w_l),1),torch.cat((v,label),0)).sigmoid_()>torch.rand(self.num_h,1,device=self.device)).float() # c.f. Eq (17)\n",
    "\n",
    "    def sample_v_given_h(self, h):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        h (torch.Tensor): the hidden states\n",
    "        \n",
    "        Returns:\n",
    "        sampled_v (torch.Tensor): the sample v according to Eq.(18). \n",
    "                                  It is a column vector that contains 0 or 1. \n",
    "\n",
    "        \"\"\"\n",
    "        return ( torch.addmm(self.b, self.w_v.t(), h).sigmoid_()>torch.rand(self.num_v, 1,device=self.device) ).float() # c.f. Eq (18)\n",
    "\n",
    "\n",
    "    def block_gibbs_sampling(self, initial_v, label, num_iter):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        initial_v (torch.Tensor): the initial visible states to start the block gibbs sampling\n",
    "        num_iter(int): the number of iterations for the gibbs sampling\n",
    "    \n",
    "        Returns:\n",
    "        gibbs_v (torch.Tensor): the sampled visible states\n",
    "        \"\"\"\n",
    "        v = initial_v.to(device=self.device)\n",
    "        label = label.to(device=self.device)\n",
    "        for _ in range(num_iter):\n",
    "            \n",
    "            h = self.sample_h_given_v(v,label)\n",
    "            v = self.sample_v_given_h(h)\n",
    "\n",
    "        return v\n",
    "\n",
    "    def free_energy_gradient(self, v, label = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        v (torch.Tensor): the visible states\n",
    "\n",
    "        Returns:\n",
    "        grad_w (torch.Tensor): the average gradient of the free energy with respect to w across all samples\n",
    "        grad_b (torch.Tensor): the average gradient of the free energy with respect to b across all samples\n",
    "        grad_c (torch.Tensor): the average gradient of the free energy with respect to c across all samples\n",
    "\n",
    "        \"\"\"\n",
    "        temp = -torch.addmm(self.c, torch.cat((self.w_v,self.w_l),1),torch.cat((v,label),0)).sigmoid_()\n",
    "\n",
    "        grad_c =  temp.mean(dim=1).unsqueeze(1)\n",
    "        grad_b = - v.mean(dim=1).unsqueeze(1)\n",
    "        grad_w_v = torch.matmul(temp,v.t())/v.size(1)\n",
    "        grad_w_l = torch.matmul(temp,label.t())/label.size(1)\n",
    "\n",
    "        # v.size(1)  == label.size(1) == batch_size\n",
    "        \n",
    "        return grad_w_v, grad_w_l, grad_b, grad_c\n",
    "\n",
    "    def mini_batch_gradient_func (self, v, cd_k,labels):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "        v (torch.Tensor): the visible states\n",
    "        cd_k (int): cd_k mode that is chosen\n",
    "\n",
    "        Returns:\n",
    "        grad_mini_batch (Torch) the average gradient across all samples in the mini-batch\n",
    "        \"\"\"\n",
    "        v = v.to(device=self.device) # move to GPU if necessary \n",
    "        \n",
    "        v_k = self.block_gibbs_sampling(initial_v = v, label = labels, num_iter = cd_k)\n",
    "        \n",
    "        [grad_w_v_pos,grad_w_l_pos, grad_b_pos, grad_c_pos] = self.free_energy_gradient(v,labels)\n",
    "        [grad_w_v_neg,grad_w_l_neg, grad_b_neg, grad_c_neg] = self.free_energy_gradient(v_k,labels)\n",
    "\n",
    "        return grad_w_v_pos - grad_w_v_neg, grad_w_l_pos - grad_w_l_neg, grad_b_pos - grad_b_neg, grad_c_pos - grad_c_neg # c.f. Eq.(13)\n",
    "\n",
    "    def train(self, dataloader, cd_k, max_epochs = 5, lr = 0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        dataloader: dataloader of the training data \n",
    "        cd_k: the contrastive divergence mode\n",
    "        max_epochs: number of epochs\n",
    "        lr: the learning rate\n",
    "\n",
    "        Returns:\n",
    "        w, b, c: the parameters of the RBM\n",
    "        \"\"\"\n",
    "        for iter in range(max_epochs):\n",
    "\n",
    "            print('Epoch {}'.format(iter))\n",
    "\n",
    "            for mini_batch_samples in dataloader:\n",
    "                mini_batch_samples_ = torch.flatten(mini_batch_samples[0].squeeze(1),start_dim=1).t().round()\n",
    "\n",
    "                labels = self.idx2onehot(mini_batch_samples[1],10).t()\n",
    "\n",
    "              \n",
    "                # we use mini_batch_samples[0] to extract the data since mini_batch_samples[1] is the label. \n",
    "                # each column in  mini_batch_samples_ is corresponding to one data sample. \n",
    "\n",
    "                grad_w_v, grad_w_l, grad_b, grad_c = self.mini_batch_gradient_func(mini_batch_samples_, cd_k, labels)\n",
    "                \n",
    "                \n",
    "                # update w, b, c\n",
    "                self.w_v -= lr * grad_w_v\n",
    "                self.w_l -= lr * grad_w_l\n",
    "                self.b -= lr * grad_b\n",
    "                self.c -= lr * grad_c\n",
    "            # break\n",
    "        \n",
    "        return self.w_v, self.w_l, self.b, self.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-517-b01d93e0a234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mw_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcd_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-516-dc1c9f93ff2f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, cd_k, max_epochs, lr)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;31m# each column in  mini_batch_samples_ is corresponding to one data sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mgrad_w_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_w_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmini_batch_gradient_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_samples_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcd_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-516-dc1c9f93ff2f>\u001b[0m in \u001b[0;36mmini_batch_gradient_func\u001b[0;34m(self, v, cd_k, labels)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mgrad_w_v_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_w_l_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_c_pos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_energy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mgrad_w_v_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_w_l_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_c_neg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_energy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_w_v_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad_w_v_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_w_l_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad_w_l_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad_b_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_c_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad_c_neg\u001b[0m \u001b[0;31m# c.f. Eq.(13)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-516-dc1c9f93ff2f>\u001b[0m in \u001b[0;36mfree_energy_gradient\u001b[0;34m(self, v, label)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \"\"\"\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrad_c\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BinaryRBM(784,64,10,device=\"GPU\")\n",
    "\n",
    "    # Load Data\n",
    "train_dataset = torchvision.datasets.MNIST(\"~\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32,shuffle = True)\n",
    "    \n",
    "    # Train\n",
    "w_v, w_l, b, c = model.train(train_loader, cd_k = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "i = iter(train_loader).next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new visible states with a random initial visible states via Gibbs sampling the RBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = torch.empty(784, 1).uniform_(0, 1).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_gen = model.block_gibbs_sampling(initial_v = i[0][0].view(-1,1).round(), label = model.idx2onehot(torch.tensor([1]),10).t(),num_iter = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(i[0][0].view(-1,1).round().view(28,28).numpy(),cmap = \"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAALZklEQVR4nO3dQail5X3H8e+vJtkYoWPFYWpMTYu7LEwRN5ViFwnWzZhFSlxNSGGyqCXdRdJFhBAIpU2XhQmRTEtqCKhVpDQRCTGr4ChWxwyJNphk4jCDTEvNKo3+u7jvyHW895475z3nvO+d//cDh3POe899378v/uZ53uc5731SVUi6+v3O1AVI2gzDLjVh2KUmDLvUhGGXmnjfJg+WxKF/ac2qKjttH9WyJ7k7yU+SvJrkgTH7krReWXaePck1wE+BjwNngWeB+6rqx3v8ji27tGbraNnvAF6tqp9V1W+AbwNHR+xP0hqNCftNwC+3vT87bHuXJMeTnEpyasSxJI00ZoBup67Ce7rpVXUCOAF246UpjWnZzwI3b3v/IeD1ceVIWpcxYX8WuDXJR5J8APg08MRqypK0akt346vqt0nuB74LXAM8VFUvr6wySSu19NTbUgfzml1au7V8qUbSwWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhMbXbJZWqVFfxk52fGPrLZlyy41YdilJgy71IRhl5ow7FIThl1qwrBLTTjPrtkau8LwXr/fcQ5+VNiTvAa8CbwF/Laqbl9FUZJWbxUt+59V1Rsr2I+kNfKaXWpibNgL+F6S55Ic3+kDSY4nOZXk1MhjSRohYwZBkvx+Vb2e5EbgKeCvq+qZPT4/bsRFrYwdoNvL1TxAV1U7/seNatmr6vXh+QLwGHDHmP1JWp+lw57k2iTXXXoNfAI4varCJK3WmNH4w8BjQ3fofcC/VtV/rKQqtTC2m76oK77Oy4BF5niv/ahr9is+mNfs2mbKsK87bFOGfS3X7JIODsMuNWHYpSYMu9SEYZea8BZXTWbs1Nkcp7fmcOzd2LJLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhPOs2sy677jcuRfYVphJfNgyy41YdilJgy71IRhl5ow7FIThl1qwrBLTTjPrj3N+Z7xReZc2xRs2aUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCefZr3JX87LIzqNfmYUte5KHklxIcnrbtuuTPJXkleH50HrLlDTWfrrx3wTuvmzbA8DTVXUr8PTwXtKMLQx7VT0DXLxs81Hg5PD6JHDviuuStGLLXrMfrqpzAFV1LsmNu30wyXHg+JLHkbQiax+gq6oTwAmAJNON5kjNLTv1dj7JEYDh+cLqSpK0DsuG/Qng2PD6GPD4asqRtC7Zx/3KDwN3ATcA54EvAf8GfAf4MPAL4FNVdfkg3k77sht/wEw5j76I8+w7q6odT8zCsK+SYT94DPvBs1vY/bqs1IRhl5ow7FIThl1qwrBLTXiLqybjaPpm2bJLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhPOs2syB3k56IPIll1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmnCevTmXXO7Dll1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmnCe/So39SqszqXPx8KWPclDSS4kOb1t24NJfpXkheFxz3rLlDTWfrrx3wTu3mH7P1bVbcPj31dblqRVWxj2qnoGuLiBWiSt0ZgBuvuTvDh08w/t9qEkx5OcSnJqxLEkjZT9DOAkuQV4sqo+Orw/DLwBFPBl4EhVfXYf+5l2tKghB+j6qaodT/pSLXtVna+qt6rqbeDrwB1jipO0fkuFPcmRbW8/CZze7bOS5mHhPHuSh4G7gBuSnAW+BNyV5Da2uvGvAZ9bY41awHvStR/7umZf2cG8Zl8Lw67tVnrNLungMexSE4ZdasKwS00YdqkJb3GdgTkvXbzo2FPWPufzNke27FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhPPsMzB2LntKc/4OgN7Nll1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmnCefQa6/nVY70ffLFt2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCefYZOMj3s+vgWNiyJ7k5yfeTnEnycpLPD9uvT/JUkleG50PrL1fSshauz57kCHCkqp5Pch3wHHAv8BngYlV9NckDwKGq+sKCfdlELWGdLbvfoLv6LL0+e1Wdq6rnh9dvAmeAm4CjwMnhYyfZ+gdA0kxd0TV7kluAjwE/Ag5X1TnY+gchyY27/M5x4Pi4MiWNtbAb/84Hkw8CPwC+UlWPJvmfqvrdbT//76ra87rdbvxy7MbrSizdjQdI8n7gEeBbVfXosPn8cD1/6br+wioKlbQe+xmND/AN4ExVfW3bj54Ajg2vjwGPr768zamqPR8H9dhJ9nxMac61XY32Mxp/J/BD4CXg7WHzF9m6bv8O8GHgF8Cnqurign3Nths/53XGxzA0/ezWjd/3NfsqGPbljj2GYe9n1DW7pIPPsEtNGHapCcMuNWHYpSa8xXVwUEfbYe/a/ZaaLrFll5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmnGffp73mqxfNVY/9U9Fj5sKdR9cltuxSE4ZdasKwS00YdqkJwy41YdilJgy71ITz7Ps0Zr7ae8o1B7bsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9TEftZnvznJ95OcSfJyks8P2x9M8qskLwyPe9Zf7sHkOuSag/2sz34EOFJVzye5DngOuBf4C+DXVfX3+z7YjJdslq4Wuy3ZvPAbdFV1Djg3vH4zyRngptWWJ2ndruiaPcktwMeAHw2b7k/yYpKHkhza5XeOJzmV5NSoSiWNsrAb/84Hkw8CPwC+UlWPJjkMvAEU8GW2uvqfXbAPu/HSmu3Wjd9X2JO8H3gS+G5VfW2Hn98CPFlVH12wH8MurdluYd/PaHyAbwBntgd9GLi75JPA6bFFSlqf/YzG3wn8EHgJeHvY/EXgPuA2trrxrwGfGwbz9tqXLbu0ZqO68ati2KX1W7obL+nqYNilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWpi00s2vwH8fNv7G4ZtczTX2uZaF1jbslZZ2x/s9oON3s/+noMnp6rq9skK2MNca5trXWBty9pUbXbjpSYMu9TE1GE/MfHx9zLX2uZaF1jbsjZS26TX7JI2Z+qWXdKGGHapiUnCnuTuJD9J8mqSB6aoYTdJXkvy0rAM9aTr0w1r6F1IcnrbtuuTPJXkleF5xzX2JqptFst477HM+KTnburlzzd+zZ7kGuCnwMeBs8CzwH1V9eONFrKLJK8Bt1fV5F/ASPKnwK+Bf760tFaSvwMuVtVXh38oD1XVF2ZS24Nc4TLea6ptt2XGP8OE526Vy58vY4qW/Q7g1ar6WVX9Bvg2cHSCOmavqp4BLl62+Shwcnh9kq3/WTZul9pmoarOVdXzw+s3gUvLjE967vaoayOmCPtNwC+3vT/LvNZ7L+B7SZ5LcnzqYnZw+NIyW8PzjRPXc7mFy3hv0mXLjM/m3C2z/PlYU4R9p6Vp5jT/9ydV9cfAnwN/NXRXtT//BPwRW2sAngP+YcpihmXGHwH+pqr+d8pattuhro2ctynCfha4edv7DwGvT1DHjqrq9eH5AvAYW5cdc3L+0gq6w/OFiet5R1Wdr6q3qupt4OtMeO6GZcYfAb5VVY8Omyc/dzvVtanzNkXYnwVuTfKRJB8APg08MUEd75Hk2mHghCTXAp9gfktRPwEcG14fAx6fsJZ3mcsy3rstM87E527y5c+rauMP4B62RuT/C/jbKWrYpa4/BP5zeLw8dW3Aw2x16/6PrR7RXwK/BzwNvDI8Xz+j2v6FraW9X2QrWEcmqu1Oti4NXwReGB73TH3u9qhrI+fNr8tKTfgNOqkJwy41YdilJgy71IRhl5ow7FIThl1q4v8BiGMnH3ZAu2sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the images\n",
    "#plt.imshow(gen_mnist_image(v_gen.t().view(10,1,28,28).numpy().round(),10),cmap = \"gray\")\n",
    "plt.imshow(v_gen.view(28,28).numpy(),cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
